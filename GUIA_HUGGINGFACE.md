# üîë Guia: Como Obter e Configurar a Chave do Hugging Face

## üìã Passo a Passo para Obter o Token

### **Passo 1: Criar Conta no Hugging Face**

1. Acesse: https://huggingface.co/
2. Clique em **"Sign Up"** (canto superior direito)
3. Preencha o formul√°rio ou use sua conta do Google/GitHub
4. Confirme seu email (verifique a caixa de entrada)

### **Passo 2: Obter o Token de Acesso**

1. Fa√ßa login na sua conta
2. Acesse: https://huggingface.co/settings/tokens
3. Clique em **"New token"**
4. Preencha:
   - **Name**: `Sistema Jur√≠dico` (ou qualquer nome)
   - **Type**: Selecione **"Read"** (para usar a API Inference gratuita)
5. Clique em **"Generate token"**
6. **IMPORTANTE**: Copie o token imediatamente! Ele s√≥ aparece uma vez.
   - Formato: `hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`

### **Passo 3: Configurar no Projeto**

#### **Op√ß√£o A: Usando arquivo .env (Recomendado)**

1. Copie o arquivo `env.example` para `.env`:
   ```bash
   cp env.example .env
   ```

2. Abra o arquivo `.env` e adicione/edite a linha:
   ```env
   HUGGINGFACE_API_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
   ```

3. Substitua `hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx` pelo seu token real

#### **Op√ß√£o B: Vari√°veis de Ambiente do Sistema**

**Windows (PowerShell):**
```powershell
$env:HUGGINGFACE_API_TOKEN="hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

**Windows (CMD):**
```cmd
set HUGGINGFACE_API_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

**Linux/Mac:**
```bash
export HUGGINGFACE_API_TOKEN="hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

### **Passo 4: Verificar Configura√ß√£o**

Ap√≥s configurar, reinicie o servidor backend:

```bash
cd backend
python -m uvicorn app.main:app --reload
```

## üéØ Limites do Tier Gratuito

### **Hugging Face Inference API (Gratuito):**
- ‚úÖ **30.000 requisi√ß√µes/m√™s** gratuitas
- ‚úÖ Sem necessidade de cart√£o de cr√©dito
- ‚úÖ Acesso a todos os modelos p√∫blicos
- ‚úÖ Sem limite de tempo

### **Modelos Dispon√≠veis Gratuitamente:**
- `distilbert-base-uncased` - An√°lise de texto
- `google/flan-t5-base` - Gera√ß√£o de texto
- `facebook/bart-large-cnn` - Resumo de texto
- `distilbert-base-uncased-finetuned-sst-2-english` - An√°lise de sentimento

## ‚ö†Ô∏è Importante

1. **N√ÉO compartilhe seu token** publicamente
2. **N√ÉO commite o arquivo `.env`** no Git (j√° est√° no .gitignore)
3. O token √© **pessoal e intransfer√≠vel**
4. Se perder o token, gere um novo em: https://huggingface.co/settings/tokens

## üîß Configura√ß√£o Alternativa (Sem Token)

Se voc√™ **N√ÉO quiser usar token** (funciona, mas com limites menores):

1. Deixe `HUGGINGFACE_API_TOKEN` vazio no `.env`:
   ```env
   HUGGINGFACE_API_TOKEN=
   ```

2. O sistema ainda funcionar√°, mas:
   - Pode ter rate limits mais restritivos
   - Alguns modelos podem n√£o estar dispon√≠veis
   - Requisi√ß√µes podem ser mais lentas

## üìù Exemplo de Configura√ß√£o Completa

```env
# ===========================================
# CONFIGURA√á√ïES DE IA (HUGGING FACE)
# ===========================================

# Token da API Hugging Face
HUGGINGFACE_API_TOKEN=hf_abc123def456ghi789jkl012mno345pqr678stu901vwx234yz

# Usar API Inference (gratuito) ou modelo local
HUGGINGFACE_MODE=api

# Modelo padr√£o para an√°lise
HUGGINGFACE_MODEL=distilbert-base-uncased

# Modelo para gera√ß√£o de texto (LLM)
HUGGINGFACE_LLM_MODEL=google/flan-t5-base

# Timeout para requisi√ß√µes (segundos)
AI_REQUEST_TIMEOUT=60

# Habilitar cache de respostas
AI_CACHE_ENABLED=true
```

## üß™ Testar a Configura√ß√£o

Ap√≥s configurar, voc√™ pode testar:

1. **Via Swagger (Recomendado):**
   - Acesse: http://localhost:8000/docs
   - V√° em `/api/v1/ai/models`
   - Clique em "Try it out" ‚Üí "Execute"
   - Deve retornar informa√ß√µes dos modelos

2. **Via C√≥digo Python:**
   ```python
   from app.services.ai_service import ai_service
   
   # Testar an√°lise de texto
   result = await ai_service.analyze_text(
       text="Este √© um texto de teste",
       task="sentiment-analysis"
   )
   print(result)
   ```

## üÜò Problemas Comuns

### **Erro: "401 Unauthorized"**
- ‚úÖ Verifique se o token est√° correto
- ‚úÖ Certifique-se de que copiou o token completo (come√ßa com `hf_`)

### **Erro: "503 Model is currently loading"**
- ‚úÖ Normal! O modelo est√° carregando
- ‚úÖ Aguarde alguns segundos e tente novamente
- ‚úÖ O sistema j√° tem retry autom√°tico

### **Erro: "Rate limit exceeded"**
- ‚úÖ Voc√™ atingiu o limite de 30k requisi√ß√µes/m√™s
- ‚úÖ Aguarde o pr√≥ximo m√™s ou considere upgrade

### **Token n√£o funciona**
- ‚úÖ Verifique se o token tem permiss√£o "Read"
- ‚úÖ Gere um novo token se necess√°rio
- ‚úÖ Certifique-se de que o `.env` est√° sendo carregado

## üìö Links √öteis

- **Documenta√ß√£o Hugging Face:** https://huggingface.co/docs/api-inference/index
- **Gerenciar Tokens:** https://huggingface.co/settings/tokens
- **Modelos Dispon√≠veis:** https://huggingface.co/models
- **Status da API:** https://status.huggingface.co/

## ‚úÖ Checklist de Configura√ß√£o

- [ ] Conta criada no Hugging Face
- [ ] Token gerado e copiado
- [ ] Arquivo `.env` criado
- [ ] Token adicionado no `.env`
- [ ] Servidor backend reiniciado
- [ ] Teste realizado via Swagger
- [ ] Funcionalidade de IA testada

---

**Pronto!** Agora voc√™ est√° configurado para usar a API do Hugging Face gratuitamente! üéâ

